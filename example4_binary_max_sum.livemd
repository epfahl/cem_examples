# Example 4: Binary max-sum

```elixir
Mix.install(
  [
    {:cem, git: "https://github.com/epfahl/cem.git"}
  ],
  force: true
)
```

## The problem

`params_to_instance` should probably take `opts`? Anything else need `opts`?

```elixir
defmodule MaxSum do
  alias CEM.Helpers
  alias CEM.Random

  def init(%{other_opts: %{n_bits: n_bits}}) do
    for _ <- 1..n_bits, do: 0.5
  end

  def draw(probs), do: for(p <- probs, do: Random.bernoulli(p))

  def score(bits), do: Enum.sum(bits)

  def update(sample) do
    n = length(sample)

    sample
    |> Enum.reduce(fn bits, sum ->
      bits
      |> Enum.zip(sum)
      |> Enum.map(fn {b, s} -> b + s end)
    end)
    |> Enum.map(&(&1 / n))
  end

  def smooth(probs, probs_prev, f_interp) do
    probs
    |> Enum.zip(probs_prev)
    |> Enum.map(fn {p, pp} -> Helpers.interpolate(p, pp, f_interp) end)
  end

  def terminate?([entry | _], %{other_opts: %{n_bits: n_bits}}) do
    score(params_to_instance(entry.params)) == n_bits
  end

  def params_to_instance(probs) do
    Enum.map(probs, fn p -> if p > 0.99, do: 1, else: 0 end)
  end
end
```

We can test these independently of `CEM`.

```elixir
%{other_opts: %{n_bits: 10}}
|> MaxSum.init()
|> MaxSum.draw()
```

```elixir
prob =
  CEM.new(
    init: &MaxSum.init/1,
    draw: &MaxSum.draw/1,
    score: &MaxSum.score/1,
    update: &MaxSum.update/1,
    smooth: &MaxSum.smooth/3,
    terminate?: &MaxSum.terminate?/2,
    params_to_instance: &MaxSum.params_to_instance/1
  )
```

```elixir
CEM.search(prob, other_opts: [n_bits: 1000])
```

You may see that the final score after `n_step_max` iterations is less than `n_bits`, the maximum score (if not, try running again). This can happen when when one or more probabilities gets prematurely set to 0 and simple smoothing is unable to change the value.

Try the run again with different values of `n_sample`, `f_smooth`, and `n_step_max`. For example, just increasing the sample size in one iteration may be sufficient to prevent premature convergence:

```elixir
CEM.search(prob, n_sample: 1000, other_opts: [n_bits: 1000])
```

This should show a higher score, and possibly a perfect score.

<!-- livebook:{"break_markdown":true} -->

This example illustrates the need to quickly explore the space of hyperparameters for each problem.
